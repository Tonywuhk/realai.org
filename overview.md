---
permalink: /overview/
---
# Overview

## AI and Society

Rapid [progress](http://realai.org/progress/) in artificial intelligence (AI) has raised the prospect that machines will [one day](http://realai.org/timing/) surpass humans in intelligence. Such AI systems are referred to as “general AI”, “strong AI”, or AGI ([artificial general intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence)). Countries have [policies](http://realai.org/policies/) in place that support AGI research and development. Capable [research groups](http://realai.org/labs/) are well-funded, some directly sponsored by the technology [industry](http://realai.org/industry/). Several AGI [roadmaps](http://realai.org/roadmaps/) have already been published by renowned experts.

The creation of AGI could mark the beginning of [technological singularity](https://en.wikipedia.org/wiki/Technological_singularity), and represent the greatest change in the history of life on Earth. It could bring enormous benefits to humanity, but could also spell disaster if not properly developed. Given its imminence and potential [impacts](http://realai.org/impacts/), the development of AGI will affect all of us, and deserves a lot more attention from the wider society.

The best place to appreciate AI’s progress is at its research frontiers. Unlike mature fields where many years of postgraduate training is needed, the [background](http://realai.org/resources/curriculum/) for cutting-edge AI is accessible to college students, whose papers often appear in top academic conferences.

We can take steps to ensure that the creation of AGI is [safe and beneficial](http://realai.org/safety/). To [positively shape AGI's development](https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/), things that can be done today include research, policy, advocacy and capacity building. Many [AI safety organizations](http://realai.org/safety/organizations/) around the world can [effectively](http://realai.org/safety/effective-altruism/) put additional human and financial resources to good use. For those who feel the urgency or are willing to contribute, there are many ways, from small donations to lifetime [career changes](https://80000hours.org/). With hard work and caution, we believe that when singularity comes, it's not going to be a disaster. It's going to be the next level of civilization. In this new world, everyone can live well and prosper.

### Near-Term Safety

In a widely cited article about the singularity, [Vinge (1993)](http://edoras.sdsu.edu/~vinge/misc/singularity.html) predicts that greater-than-human intelligence will occur during the next 30 years. In this website, near-term safety is about keeping AGI safe and beneficial if it will be created by the end of 2023. A plausible path of such a development is the [Prosaic AI](http://realai.org/prosaic/) scenario, in which we can scale up existing [deep learning](https://en.wikipedia.org/wiki/Deep_learning) methods to build AGI, without the help of qualitatively new ideas about how intelligence works.

## Technical Contents

Broadly speaking, whenever we apply deep neural networks to machine learning problems, we’re in the realm of deep learning. At present, however, deep learning usually refers to a narrower set of areas that are immediately productive for real-world applications, such as computer vision and natural language processing. A common property shared by these areas is that machine intelligence is only applied to short-horizon tasks. No substantial efforts are made to model the time dimension of intelligence, leading to the widespread misconception that deep learning’s capabilities are too limited for AGI, since a system isn’t considered intelligent if it has no strategic element to properly understand time. Many deep learning experts today believe that AGI is at least decades away if at all possible.

Since 2013, deep learning methods have significantly accelerated progress in reinforcement learning, leading to a young field of its own called deep reinforcement learning (DRL). DRL research directly addresses core challenges on the path to AGI, especially on the time dimension, such as [reasoning](http://realai.org/reasoning/) and [planning](http://realai.org/planning/). Unlike “timeless” deep learning, however, DRL has yet to find compelling commercial applications and is mainly used in the domain of [games](http://realai.org/environments/#games). Here and elsewhere on this site, we normally use the narrow interpretation of deep learning, in order to clearly distinguish it from DRL, which is not widely used in everyday life at present, but has enormous near-term potential towards AGI.

The remainder of the site is organized as follows: The [Background](http://realai.org/background/) section covers academic disciplines that are relevant to understanding AI based on science and reasoning. The [Course](http://realai.org/course/) section provides a technical foundation for readers to understand and implement frontline research results. [Machine Learning](http://realai.org/machine-learning/) contains brief surveys of relevant fields that support the identification of an academic area that will most likely lead to the first successful AGI development. At present, these surveys point to one area, [Deep Reinforcement Learning](http://realai.org/deep-reinforcement-learning/), for which we conduct an extensive literature review. Finally we describe our own Research that is not yet covered by the existing literature.

## References

* 1993, Vernor Vinge. [The Coming Technological Singularity: How to Survive in the Post-Human Era](http://edoras.sdsu.edu/~vinge/misc/singularity.html). *VISION-21 Symposium*.

