---
---
# DQN Agent on CartPole

*Last Updated: October 5, 2017*

Reinforcement learning agents in OpenAI Gym can be trained and run in the cloud. Here we describe a very simple example where a DQN agent is trained to play [CartPole-v0](https://gym.openai.com/envs/CartPole-v0/) on [Google Cloud](../google-cloud-platform/README.md). First we create a virtual machine:

* [Machine type](https://cloud.google.com/compute/pricing#predefined_machine_types): n1-highcpu-8
* Boot disk: [Ubuntu](../ubuntu.md) 16.04 LTS
* Firewall: Allow HTTP traffic

Here we allow HTTP traffic in order to later download the MP4 files generated by running the trained agent in OpenAI Gym. Next we install Mini[conda](../conda.md):

```bash
wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh
source ~/.bashrc
rm Miniconda3-latest-Linux-x86_64.sh
```

Basic libraries required for this experiment include [OpenAI Gym](https://github.com/openai/gym), [TensorFlow](https://github.com/tensorflow/tensorflow) and [OpenAI Baselines](https://github.com/openai/baselines). All of them are open source:

```bash
pip install gym
pip install tensorflow
pip install baselines
```

At this point, the agent can already be trained in the cloud. A [sample script](https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_cartpole.py) is included in the OpenAI Baselines library to train a DQN agent:

```bash
python -m baselines.deepq.experiments.train_cartpole
```

generates a trained model `cartpole_model.pkl` in the home directory. But without a monitor, we cannot yet see how the agent performs in video. We will need a few tools to render the environment in which our agent acts. [python-opengl](https://packages.ubuntu.com/xenial/python-opengl) is the Python bindings to OpenGL, [ffmpeg](https://packages.ubuntu.com/xenial/ffmpeg) contains tools for making movies, and [xvfb](https://packages.ubuntu.com/xenial/xvfb) allows us to fake a monitor: 

```bash
sudo apt update
sudo apt install python-opengl
sudo apt install ffmpeg
sudo apt install xvfb
```

OpenAI Baselines contains another [sample script](https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/enjoy_cartpole.py) to display the trained agent playing CartPole on a local monitor. Since we're running this experiment in the cloud, we'll need to use our own [revised version](https://github.com/real-ai/realai.org/blob/master/course/reinforcement-learning/mp4-cartpole.py) of their script to generate MP4 files instead. We'll download this script from the web, then run it using the fake monitor provided by `xvfb-run`:

```bash
wget http://realai.org/course/reinforcement-learning/mp4-cartpole.py
xvfb-run -s "-screen 0 1400x900x24" bash
python mp4_cartpole.py 
cd /tmp/CartPole
sudo python3 -m http.server 80
```

The last line above sets up a HTTP server so that now we can download MP4 files from the web. [Here](DQN-agent-on-CartPole-1.mp4) is one of the files generated following the instructions above.

