---
permalink: /timing/
---
# Timing

In recent years there has been rapid [progress](http://realai.org/progress/) towards the creation of AGI, to the extent that [roadmaps](http://realai.org/roadmaps/) are under serious dicussion. Given SI's potentially huge impact and its technological proximity to AGI, it is of paramount importance to form rational expectations on timing.

## Links

* AI Impacts: [Guide to pages on AI timeline predictions](http://aiimpacts.org/guide-to-pages-on-ai-timeline-predictions/). Updated April 7, 2017.
* Open Philanthropy: [What should we learn from past AI forecasts?](http://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/what-should-we-learn-past-ai-forecasts). Updated September, 2016.
* Open Philanthropy: [What Do We Know about AI Timelines?](http://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/ai-timelines). Updated July, 2016.

## Survey Results

* 2017 May 24, Survey: 50% chance of high-level machine intelligence occurring before **2061** (median). Source: Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. [When Will AI Exceed Human Performance? Evidence from AI Experts](https://arxiv.org/abs/1705.08807). *arXiv:1705.08807*.

* 2016 September 20, Oren Etzioni: 92.5% of AAAI survey respondents think superintelligence will arrive after **2041**. Source: [No, the Experts Don’t Think Superintelligent AI is a Threat to Humanity](https://www.technologyreview.com/s/602410/no-the-experts-dont-think-superintelligent-ai-is-a-threat-to-humanity/). *MIT Technology Review*.
   * 2016 November 2, Dafoe & Russell argue that the survey results are consistent with the ones Bostrom cites (below). Source: [Yes, We Are Worried About the Existential Risk of Artificial Intelligence](https://www.technologyreview.com/s/602776/yes-we-are-worried-about-the-existential-risk-of-artificial-intelligence/). *MIT Technology Review*.

* 2014, Survey: high-level machine intelligence in **2040** (median). Source: Vincent C. Müller and Nick Bostrom. [Future Progress in Artificial Intelligence: A Survey of Expert Opinion](http://www.nickbostrom.com/papers/survey.pdf). *Fundamental Issues of Artificial Intelligence*.

## AI Expert Opinions

### Geoffrey E. Hinton

[Geoffrey Hinton](http://www.cs.toronto.edu/~hinton/) predicted in a [Guardian report](https://www.theguardian.com/science/2015/may/21/google-a-step-closer-to-developing-machines-with-human-like-intelligence) on 21 May 2015 that computers would have developed "common sense" within a decade. In that report, "reasoning and logic" were understood as part of common sense. In an [O'Reilly report](https://www.oreilly.com/ideas/adapting-ideas-from-neuroscience-for-ai) published on 28 March 2017, he said it might take longer than 10 years to develop systems that surpass people in areas like "reasoning and learning from a very small number of examples."

### Jürgen Schmidhuber

During the [Beneficial AI 2017](https://futureoflife.org/bai-2017/) conference, [Jürgen Schmidhuber](http://people.idsia.ch/~juergen/) predicted on 7 January 2017 in a panel discussion about creating human-level AI that it would happen before his retirement, which would be 2028 under the current swiss law, but could be postponed in the event of a law change. The discussion's [video recording](https://youtu.be/V0aXMTpZTfc?t=6m54s) was published on 9 Feb 2017. He later explained in a [Guardian report](https://www.theguardian.com/technology/2017/apr/18/robot-man-artificial-intelligence-computer-milky-way) on 18 April 2017 that his company [Nnaisense](https://nnaisense.com/) was already developing systems that function like babies. They are too slow, but assuming hardware progress of 10 times faster every five years, he said it would "only take 25 years" to have a neural net comparable with the human brain. He reiterated in an [IEEE report](http://spectrum.ieee.org/computing/software/humanlevel-ai-is-right-around-the-corner-or-hundreds-of-years-away#JurgenSchmidhuber) on 31 May 2017 that "soon" we'd have cheap devices with the raw computational power of a human brain.

### Demis Hassabis

* 2016 February 16, Demis Hassabis: decades away from general intelligence. Source: [The superhero of artificial intelligence: can this genius keep it in check?](https://www.theguardian.com/technology/2016/feb/16/demis-hassabis-artificial-intelligence-deepmind-alphago). *The Guardian*.

### Yoshua Bengio

[Yoshua Bengio](http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html) said on 15 June 2017 ([video](https://youtu.be/IZGobhDoBCg?t=5h27m5s)) during the [4th Annual Canada 2020 Conference](http://canada2020.ca/events/4th-annual-canada-2020-conference/) that we're very far away from human-level AI, not just because of computing power, but also the basic level of understanding of science.

### Machine Intelligence Research Institute

* 2017 April 30. Research staff at MIRI assigned moderately higher probability to AGI’s being developed before 2035 than they did a year or two ago. Source: [2017 Updates and Strategy](https://intelligence.org/2017/04/30/2017-updates-and-strategy/). *Machine Intelligence Research Institute*.

* 2013 May 15, Luke Muehlhauser. [When Will AI Be Created?](https://intelligence.org/2013/05/15/when-will-ai-be-created/). *Machine Intelligence Research Institute*.

### Ray Kurzweil

Ray [Kurzweil](http://www.kurzweilai.net/) predicted in his 2005 book [The Singularity Is Near: When Humans Transcend Biology](http://singularity.com/) that strong AI would emerge around 2029. He has kept his prediction since then, and in an [IEEE report](http://spectrum.ieee.org/computing/software/humanlevel-ai-is-right-around-the-corner-or-hundreds-of-years-away#RayKurzweil) on 31 May 2017, reiterated his belief that computer would exceed human capabilities by 2029. He elaborated further in a [video](https://futurism.com/videos/ray-kurzweil-singularity-will-arrive-by-2045/) that 2029 is the year he believes "we will have completed the reverse engineering of the human brain." Note that building AGI doesn't necessarily requires that.

As of August 2017, Kurzweil leads a team of about 35 people at Google that powers Smart Reply, according to [Wired](https://www.wired.com/story/what-is-ray-kurzweil-up-to-at-google-writing-your-emails/).

### Nick Bostrom

As of [31 May 2017](http://spectrum.ieee.org/computing/software/humanlevel-ai-is-right-around-the-corner-or-hundreds-of-years-away#NickBostrom), the notion that we could have human-level AI within a small number of decades seemed reasonable to Nick Bostrom.

### Gary Marcus

As of [31 May 2017](http://spectrum.ieee.org/computing/software/humanlevel-ai-is-right-around-the-corner-or-hundreds-of-years-away#GaryMarcus), Gary thought it could still be 20 to 50 years before machines can be as fluent as people in a few cognitive areas.

### Wei Xu

AI Era (新智元) [reported in April 2017 on WeChat](http://mp.weixin.qq.com/s/TM0SrdQiAkwTqY4JhNZ9cQ) that Wei Xu ([徐伟](http://idl.baidu.com/IDL-team.html)) from Baidu's IDL predicted more than 50% chance of AGI creation before 2050.

### Other Sources

According to a [tweet](https://twitter.com/katherinebailey/status/860188371888549888) posted by Twitter account [@katherinebailey](https://twitter.com/katherinebailey) on 5 May 2017, two persons from Amazon's AI team separately gave estimates of 10-15 years before AGI would be created.

## Business Leader Opinions

In July 2017, **Kai-Fu Lee** [wrote](https://www.wired.com/story/a-blueprint-for-coexistence-with-artificial-intelligence/) on Wired that he didn't expect to see engineering algorithms for "General AI" any time soon, and claimed that "continued exponential growth requires scientific breakthroughs that are unlikely to be solved for a hundred years."

Responding to the [survey results](https://arxiv.org/abs/1705.08807) mentioned in the [earlier section](http://realai.org/timing/#survey-results), Elon Musk [tweeted in June 2017](https://twitter.com/elonmusk/status/871886151014940672) that based on exponential progress, AI will be able to beat humans closer to 2030 to 2040 instead of 2060, which would be linear extrapolation.

According to a February 2017 [TechCrunch report](https://techcrunch.com/2017/02/27/superintelligent-ai-explains-softbanks-push-to-raise-a-100bn-vision-fund/), Softbank CEO **Masayoshi Son** believed that in 30 years, the world would see singularity, in the form of superintelligence robots.

Alphabet co-founder **Sergey Brin** said in January 2017 that the AI revolution had been very profound and surprised him, according to [a report by Bloomberg Technology](https://www.bloomberg.com/news/articles/2017-01-19/google-s-sergey-brin-surprised-by-speed-of-ai-advancements).

## Predictions Based on Computational Power

In July 2015, Tim Dettmers [estimated](http://timdettmers.com/2015/07/27/brain-vs-deep-learning-singularity/) that we would reach the brain's computational power in 2078. He also presented scenarios in which we'd reach it earlier, in 2037 and 2053.

## Speed of Improvement

WaveNet was [introduced on September 8, 2016](https://deepmind.com/blog/wavenet-generative-model-raw-audio/), when it needed 1 second to generate just 0.02 seconds of audio. By [October 4, 2017](https://deepmind.com/blog/wavenet-launches-google-assistant/), it can produce 20 seconds of higher quality audio in 1 second, that is "1,000 times faster" and better.

