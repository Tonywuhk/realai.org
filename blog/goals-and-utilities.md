---
permalink: /blog/goals-and-utilities/
---
# Goals and Utilities

The question of how to do most good is often brought up in the context of [effective altruism](http://realai.org/safety/effective-altruism/) and discussions about it almost always involve goals and utilities. Below we present a short commentary regarding these topics:

First a little background: there is an ultimate reality, which can be the entire universe, the Everett many-worlds, the Bostrom simulation, or the Deutsch omega point. Whatever it is, its a complex entity of which the full understanding is obviously way beyond human capacity. Being reasonably intelligent, we model our limited understanding of reality by the concept of uncertainty, we admit there are things we don't know. Most uncertainties we attribute to randomness, but for a small subset of uncertainties concerning complex systems like ourselves, we use the concept of choice. Even though there is no physical law that specifically applies to choice, it has been a very useful model to make sense of human behavior. Mathematically, any system that is modelled by choice can also be described by a utility function. Whatever choice a system makes, there is always a mathematical function such that the choice made happens to maximize this function, among all other counterfactual choices that, by our model, also can be made by the system. This mathematical function almost surely has no semantic basis because the size of the space of all functions is a higher order of infinity than that of computable functions, which is a prerequisite for them to be human understandable. Again, this barrier doesn't stop us. Within the set of understandable functions, we can find one that is reasonably close to the mathematical utility function, we can describe it in short paragraphs of natural language, and that description is what commonly understood as goal.

Therefore, there are at least four levels of abstraction between a typical casual worldview we use every day and the ultimate reality, these are: uncertainty, choice, utility, and goal. At the level of goal, it is a very inadequate model for non-human complex behavior, especially for understanding the drives and motivations of superintelligent AGIs.

Returning to the question of how to do most good, since our intellectual capacity is confined by physiology, we can only hope to understand a goal that is as close to the mathematical utility function as possible. Being altruistic means that utility function reflects the choices of the collective behavior of a very broadly defined entity, which at least has to include all humans, and can be as big as all of reality. This is different from helping each individual achieve their own respective goals.

Said more simply, the practice of effective altruism is about using evidence and reason to infer the goal that models the collective behavior of at least all humans, then act rationally to help achieve that goal.

