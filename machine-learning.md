---
permalink: /machine-learning/
redirect_from: /ML/
---
# Machine Learning

The most crucial ability of an intelligent system is the ability of learning. To achieve AGI, it is widely believed that several objectives need to be accomplished:

* Unsupervised Learning: supervision should not be necessary as the system learns autonomously, often driven by [intrinsic motivations](http://realai.org/intrinsic-motivation) such as [prediction](http://realai.org/predictive-learning/).
* [Multi-Task Learning](http://realai.org/multi-task-learning/): the system can learn multiple tasks, continuously or perhaps throughout its life of operation, and transfer knowledge learned from some tasks to others.
* [Hierarchical Learning](http://realai.org/hierarchical-learning/): the system can understand data in a hierarchical way, including learning useful abstract concepts.
* [Meta-Learning](http://realai.org/meta-learning/): the system can improve its own learning architecture by learning how to learn.

As a result, the system should have the ability of reasoning, attention, and memory, build an internal world model, and understand language in a way that is [grounded](http://realai.org/symbol-grounding/) in this model.

Since 2012, deep learning has achieved phenomenal success or shown great potential in many areas, e.g., [vision](http://realai.org/computer-vision/), language, autonomous driving, [program induction](http://realai.org/program-induction/), and [automated theorem proving](http://realai.org/automated-theorem-proving/). Although we still lack a deep [theoretical understanding](http://realai.org/deep-learning-theory/) of how this is accomplished, we have already implemented many [deep learning systems](http://realai.org/deep-learning/implementation/). Advances in deep learning currently power many applications at production-scale.

Presently, we focus on deep learning, an area in machine learning inspired by [neuroscience](http://realai.org/background/neuroscience/). Our focus will shift to other areas if they show more promise towards AGI.

### Deep Learning

An architecture in deep learning ([Goodfellow et al., 2016](https://mitpress.mit.edu/books/deep-learning); [LeCun et al., 2015](http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html); [Schmidhuber 2014](https://arxiv.org/abs/1404.7828)) is a large and complex [network architecture](http://realai.org/network-architecture/) whose dynamics follow [learning rules](http://realai.org/learning-rules). In the architecture, there can be one or more neural networks, an agent, or [multiple agents](http://realai.org/multi-agent-learning/). Their learning can be cooperative or [adversarial](http://realai.org/adversarial-learning/). The neural networks are usually deep and hierarchical, sometimes augmented with [memory](http://realai.org/memory/), and can be automatically designed using [architecture search](http://realai.org/architecture-search/).

Deep learning has seen many applications in reinforcement learning, contributing to breakthroughs in [games](http://realai.org/environments/#games) such as Atari, Go, and Poker. Their intersection, [deep reinforcement learning](DRL/README.md) is a rapidly growing area of research today.

## References

* 2016 November, Ian Goodfellow, Yoshua Bengio, and Aaron Courville. [Deep Learning](https://mitpress.mit.edu/books/deep-learning). *The MIT Press*. [site](http://www.deeplearningbook.org/).
* 2015 February 25, Yann LeCun,	Yoshua Bengio, and Geoffrey Hinton. [Deep Learning](http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html). *Nature*, 521(7553):436-444. [PDF](https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf).
* 2014 April 30, JÃ¼rgen Schmidhuber. [Deep Learning in Neural Networks: An Overview](https://arxiv.org/abs/1404.7828). *arXiv:1404.7828*.

